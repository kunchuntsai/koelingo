## 1. User Journey

### 1.1 High-level
It's a MacBookPro Desktop application that is able to listening to Japanese speech
- generate Japanese scripts (speech-to-text) and show on UI in real-time
- translate Japanese scripts to English scripts and show on UI in real-time
- save both Japanese scripts and English scripts in a document when the application is closed

### 1.2 Step-by-step
- A start listening button: Turn on the microphone and start stt(speech-to-text)
- A stop listening button: turn on/off microphone and stop stt(speech-to-text)
- A Japanese text window: Show the speech in Japanese
- A English text window: Show translated scripts in English; translation is on by default, it will translate whatever shows up in the Japanese text window
- A Save&Close button: Save both Japanese and English scripts in a document then terminate the app.

The app is able to listen to the speech all the time as long as the "start listening" button was clicked


### 1.3 Technical requirement
- Local LLM
- MacBookPro M4 Chip

## 2. System Architecture

### 2.1 Dataflow

Audio data -> Speech to text -> UI
                  |-> Translation -> UI


### 2.2 Building blocks

<TODO>

### 2.3 Modules & Library

- Audio
- speech-to-text: whisper
- translation: LLM (nllb)
- UI: QT


## 3. Implementation plan

Four main modules: Audio, Speech to text, Translation, UI

Implement & Verify graduately as follow:
1. Audio by Unit Test
2. Audio + STT by Unit Test & UI
3. Translation by Unit Test
4. Audio + STT + Translation by Unit Test & UI
